{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ips(df: DataFrame) -> None:\n",
    "    \"\"\"Analisa e mostra os 10 maiores acessos por IP.\"\"\"\n",
    "\n",
    "    ip_counts = (df\n",
    "                .groupBy('ip')\n",
    "                .agg(F.count('*').alias('count'))\n",
    "                .orderBy('count', ascending=False)\n",
    "                .limit(10))\n",
    "    print(\"Top 10 IPs:\")\n",
    "    ip_counts.show()\n",
    "    #Mais formatado\n",
    "    for idx, row in enumerate(ip_counts.collect(), 1):\n",
    "        print(f\"{idx}º - {row['ip']}, com {row['count']} requests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_endpoints(df: DataFrame) -> None:\n",
    "    \"\"\"Analisa e mostra os 6 endpoints mais acessados, excluindo arquivos.\"\"\"\n",
    "\n",
    "    extensions = [\"css\", \"js\", \"html\", \"png\", \"jpg\", \"jpeg\", \"gif\", \"ico\", \"php\", \"txt\"]\n",
    "    pattern = r\"(?i)\\.(\" + \"|\".join(extensions) + r\")($|\\?)\"  \n",
    "\n",
    "    endpoints_counts = (df\n",
    "                    .filter(~F.col('path').rlike(pattern))\n",
    "                    .groupBy('path')\n",
    "                    .agg(F.count('*').alias('count'))\n",
    "                    .orderBy(F.desc('count'))\n",
    "                    .limit(6))\n",
    "\n",
    "    print(\"\\nTop 6 Endpoints (excluindo arquivos):\")\n",
    "    endpoints_counts.show()\n",
    "    \n",
    "    for idx, row in enumerate(endpoints_counts.collect(), 1):\n",
    "        print(f\"{idx}º - '{row['path']}', com {row['count']} acessos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_stats(df: DataFrame) -> None:\n",
    "    \"\"\"Analisa e mostra a quantidade de Client IPs distintos e a quantidade de dias representados no arquivo.\"\"\"\n",
    "\n",
    "    unique_ips = df.select('ip').distinct().count()\n",
    "    print(\"\\nQuantidade de Client IPs Distintos:\", unique_ips)\n",
    "\n",
    "    unique_days = (df\n",
    "                .select(F.regexp_extract(F.col('timestamp'), r'(\\d{2}/\\w{3}/\\d{4})', 1).alias('date_str'))\n",
    "                .filter(F.col('date_str') != \"\")\n",
    "                .distinct()\n",
    "                .count())\n",
    "    print(\"\\nQuantidade de Dias Representados:\", unique_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bytes_statistics(df: DataFrame) -> None:\n",
    "    \"\"\"Analisa alguns dados relacionados aos bytes retornados.\"\"\"\n",
    "\n",
    "    total_bytes = df.agg(F.sum('size').alias('total_bytes')).collect()[0][0]\n",
    "    max_bytes = df.agg(F.max('size').alias('max_bytes')).collect()[0][0]\n",
    "    min_bytes = df.filter(F.col('size') > 0).agg(F.min('size').alias('min_bytes')).collect()[0][0]\n",
    "    avg_bytes = df.agg(F.avg('size').alias('avg_bytes')).collect()[0][0]\n",
    "\n",
    "    print(\"\\nVolume Total de Bytes Retornados:\", total_bytes)\n",
    "    print(\"\\nMAIOR Volume de Dados em uma Única Resposta:\", max_bytes)\n",
    "    print(\"\\nMENOR Volume de Dados em uma Única Resposta:\", str(min_bytes))\n",
    "    print(\"\\nVolume Médio de Dados Retornado (arredondado):\", round(avg_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_statistics(df: DataFrame) -> None:\n",
    "    \"\"\"Analisa e mostra o dia com mais erros (4xx).\"\"\"\n",
    "\n",
    "    error_df = (df\n",
    "        .filter(F.col(\"status\").cast(\"integer\").between(400, 499))\n",
    "        #Poderia usar a coluna de dat_ref_carga, mas num cenário ideal, usuaria a o timestamp do arquivo.\n",
    "        .withColumn(\n",
    "            \"date_parsed\",\n",
    "            F.to_date(F.regexp_extract(F.col(\"timestamp\"), r\"(\\d{2}/\\w{3}/\\d{4})\", 1), \"dd/MMM/yyyy\") \n",
    "        )\n",
    "        .withColumn(\"weekday\", F.date_format(F.col(\"date_parsed\"), \"EEEE\")))\n",
    "\n",
    "    weekday_errors = (error_df\n",
    "                    .groupBy(\"weekday\")\n",
    "                    .agg(F.count('*').alias(\"error_count\"))\n",
    "                    .orderBy(F.desc(\"error_count\"))\n",
    "                    .limit(1))\n",
    "    \n",
    "    top_weekday_error_row = weekday_errors.collect()[0]\n",
    "    print(f\"\\nDia da semana com o maior número de erros (4xx): {top_weekday_error_row['weekday']}, com {top_weekday_error_row['error_count']} erros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Analisa o dataframe e retorna resultados para as seguintes perguntas:\n",
    "        - 10 maiores acessos por IP\n",
    "        - 6 Endpoints mais acessados, excluindo arquivos\n",
    "        - Quantidade de Client IPs distintos\n",
    "        - Quantos dias de dados estão representados no arquivo?\n",
    "        - Volume total de bytes retornados\n",
    "        - MAIOR volume de dados em uma única resposta\n",
    "        - MENOR volume de dados em uma única resposta\n",
    "        - Volume médio de dados retornado.\n",
    "        - Maior número de erros\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): O DataFrame processado pela função anterior.\n",
    "\n",
    "    Returns:\n",
    "        None (a informação é exibida apenas)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se o DAtaframe estiver vazio ou faltar colunas\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        raise ValueError(\"DataFrame não pode ser vazio\")\n",
    "\n",
    "    required_columns = {'ip', 'path', 'timestamp', 'size', 'status'}\n",
    "    missing_columns = required_columns - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "\n",
    "    get_top_ips(df)\n",
    "    get_top_endpoints(df)\n",
    "    get_unique_stats(df)\n",
    "    get_bytes_statistics(df)\n",
    "    get_error_statistics(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
